{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ac259f0e-46c1-4537-8264-9ad4951a755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "036d9a6c-3e2c-4144-a486-af871777f066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nThey were, and even if Washington might cons...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>We run \"SpaceNews &amp; Views\" on our STAREACH BBS...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\n\\n\\nNot to worry.  The Masons have been demo...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Only Brendan McKay, or maybe ARF, would come t...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Help: I am running some sample problems from O...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>9228</td>\n",
       "      <td>\\n\\nPrecisely, why not Cuba??  Why not???  The...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>9229</td>\n",
       "      <td>Your Custom Resume On Disk!\\n \\n              ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>9230</td>\n",
       "      <td>Throughout the years of the Israel/Arab-Palest...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>9231</td>\n",
       "      <td>Does anyone know if there are any devices avai...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>9232</td>\n",
       "      <td>\\n\\n      Give ME a break, chum.  Are you tell...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9233 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  target\n",
       "0        0  \\nThey were, and even if Washington might cons...      10\n",
       "1        1  We run \"SpaceNews & Views\" on our STAREACH BBS...      14\n",
       "2        2  \\n\\n\\nNot to worry.  The Masons have been demo...      19\n",
       "3        3  Only Brendan McKay, or maybe ARF, would come t...      17\n",
       "4        4  Help: I am running some sample problems from O...       5\n",
       "...    ...                                                ...     ...\n",
       "9228  9228  \\n\\nPrecisely, why not Cuba??  Why not???  The...      17\n",
       "9229  9229  Your Custom Resume On Disk!\\n \\n              ...       6\n",
       "9230  9230  Throughout the years of the Israel/Arab-Palest...      17\n",
       "9231  9231  Does anyone know if there are any devices avai...       4\n",
       "9232  9232  \\n\\n      Give ME a break, chum.  Are you tell...      18\n",
       "\n",
       "[9233 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nThe VL-IDE Adapter can be much faster then t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\n\\nYeah.  In a fire that reportedly burned ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>:Judge: \"I grant you immunity from whatever ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I, too, put a corbin seat on my Hawk.  I got t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\\n\\nDo I ever!!!!!!  After 2 years of having h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>9228</td>\n",
       "      <td>\\n\\n\\n\\nIn Texas, you cannot carry a handgun. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>9229</td>\n",
       "      <td>\\n Yes, I want to concentrate on other develop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>9230</td>\n",
       "      <td>\\nAll I know is that the Megadrives worked per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>9231</td>\n",
       "      <td>\\n\\nOops! Quite right. I got so busy that I sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>9232</td>\n",
       "      <td>\\nThis is actually more like the stuff from Ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text\n",
       "0        0  \\nThe VL-IDE Adapter can be much faster then t...\n",
       "1        1  \\n\\nYeah.  In a fire that reportedly burned ho...\n",
       "2        2  :Judge: \"I grant you immunity from whatever ma...\n",
       "3        3  I, too, put a corbin seat on my Hawk.  I got t...\n",
       "4        4  \\n\\nDo I ever!!!!!!  After 2 years of having h...\n",
       "...    ...                                                ...\n",
       "9228  9228  \\n\\n\\n\\nIn Texas, you cannot carry a handgun. ...\n",
       "9229  9229  \\n Yes, I want to concentrate on other develop...\n",
       "9230  9230  \\nAll I know is that the Megadrives worked per...\n",
       "9231  9231  \\n\\nOops! Quite right. I got so busy that I sa...\n",
       "9232  9232  \\nThis is actually more like the stuff from Ph...\n",
       "\n",
       "[9233 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")\n",
    "display(train,test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7a10c0e0-dc63-4825-9827-da759e261b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bed2cfe7-3729-4fc0-a3be-eab26fa92371",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tk = Tokenizer()\n",
    "tk.fit_on_texts(all_data[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b32e4e5c-5f68-46b2-a643-9cf81ddf03f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27, 63, 5, 113, 25, 898, 190, 597, 20197, 4, 16784, 325, 60973, 10, 1181, 8, 4, 2256, 26425, 51, 80, 4, 853, 5, 7653, 16784, 145, 78, 61, 1767]\n"
     ]
    }
   ],
   "source": [
    "text = tk.texts_to_sequences(all_data[\"text\"])\n",
    "print(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "693ca711-116f-4ede-8e07-96a1ad010e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         30\n",
       "1         95\n",
       "2        216\n",
       "3        213\n",
       "4        143\n",
       "        ... \n",
       "18461    125\n",
       "18462     44\n",
       "18463     78\n",
       "18464     94\n",
       "18465     20\n",
       "Length: 18466, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_len = pd.Series(text).apply(len)\n",
    "text_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc9b20f8-ca2b-4ec0-9c71-3d0995dd444b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1000.0)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWcAAAFgCAYAAABnvbg1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAY5ElEQVR4nO3df9BtVX3f8fcHCBC18YIyDF5QcGRiqW0qc6P8yLSORL1SG2xH7b114q0hvTrFRGOmBvQPajtpder4K5NQ7ggROxY0hBTiWChBkkwLotcfg/zQcNUolwFBBaxxopLn2z/Oeu49HJ6fl+ecs55z3q+ZM8/ea69zztqz4XP2XXvttVNVSJL6cti0GyBJeiLDWZI6ZDhLUocMZ0nqkOEsSR06YtoNGIft27fX9ddfP+1mSJo/2agPmskz5+9+97vTboIkPSkzGc6StNkZzpLUIcNZkjpkOEtShwxnSeqQ4SxJHTKcJalDhrMkdchwlqQOGc6S1CHDWZI6ZDhLUocMZ0nq0ExOGboeow+4TTZsxj9JOmSeOQM7Lr2FHZfeMu1mSNIBc3/mDIBny5I645mzJHXIcJakDhnOktQhw1mSOmQ4S1KHDGdJ6pDhLEkdMpwlqUOGsyR1yHCWpA4ZzpLUIcNZkjo0NxMfjU4NCk4PKqlfcxPOMJgalASquOpNZ027OZK0rLkKZxKS8MRzaEnqi33OktQhw1mSOjS2cE5yeZIHk9wxVPZfk3w1ye1J/iTJlqFtFyXZl+RrSV4xVL69le1LcuG42itJPRnnmfNHge0jZTcCL6iqfwT8FXARQJLTgB3AP2jv+YMkhyc5HPh94JXAacDOVleSZtrYwrmq/hL4/kjZ/66qx9rqZ4ET2/J5wFVV9eOq+iawD3hRe+2rqm9U1U+Aq1pdSZpp0+xz/jXgf7XlrcC9Q9v2t7Llyp8gye4ke5Psfeihh8bQXEmanKmEc5J3AY8BH9+oz6yqPVW1raq2HXfccRv1sZI0FRMf55zk3wCvAs6pg7ft3QecNFTtxFbGCuWHrKoO3DG41J2DkjRtEw3nJNuBdwD/tKp+NLTpOuB/JHk/8CzgVOBzQIBTk5zCIJR3AP96I9qyc8+tkFALC+QwRxRK6svYwjnJlcBLgGcm2Q9czGB0xlHAjW1ei89W1Zur6s4knwTuYtDdcUFV/V37nLcANwCHA5dX1Z0b1MDB3YLOryGpQ2ML56rauUTxZSvU/13gd5co/zTw6Q1smiR1z3/PS1KHDGdJ6pDhLEkdmq8pQ1cwPLxukZPxS5oWw3nI4vA6J+OXNG2G8zAn45fUCfucJalDhrMkdchwlqQOGc6S1CHDWZI6ZDhLUocMZ0nqkOEsSR0ynCWpQ4azJHXIcJakDhnOktQhw1mSOmQ4S1KHDGdJ6pDhLEkdMpwlqUOGsyR1yHCWpA4ZzpLUIcNZkjpkOEtShwxnSeqQ4SxJHTKcJalDhrMkdchwlqQOGc6S1CHDWZI6ZDhLUocMZ0nqkOEsSR0aWzgnuTzJg0nuGCo7NsmNSe5pf49p5Uny4ST7ktye5PSh9+xq9e9Jsmtc7ZWknozzzPmjwPaRsguBm6rqVOCmtg7wSuDU9toNXAKDMAcuBl4MvAi4eDHQJWmWjS2cq+ovge+PFJ8HXNGWrwBePVT+sRr4LLAlyQnAK4Abq+r7VfUwcCNPDPxxtP0JL0mapCMm/H3HV9X9bfkB4Pi2vBW4d6je/la2XPkTJNnN4KybZz/72U+6oTv33AoJVHHVm8560p8nSesxtQuCNTgd3bBT0qraU1Xbqmrbcccd9+Q/MCHJIKAlacImHc7fad0VtL8PtvL7gJOG6p3YypYrXxO7JiRtVpPu1rgO2AW8p/29dqj8LUmuYnDx79Gquj/JDcB/HroI+HLgovV84Y5Lb4GEWlgghzlyUNLmMLZwTnIl8BLgmUn2Mxh18R7gk0nOB74FvK5V/zRwLrAP+BHwRoCq+n6S/wR8vtX7j1U1epFxtYaQhLJ7QtImMrZwrqqdy2w6Z4m6BVywzOdcDly+gU1bl6W6RGLQSxqzSXdrbEqO3JA0aYbzWix2jUy7HZLmhlfIJKlDhrMkdchwlqQOGc6S1CHDWZI6ZDhLUocMZ0nqkOEsSR0ynCWpQ4azJHXIcJakDhnOktQhw1mSOmQ4S1KHDGdJ6pDhLEkdMpwlqUOGsyR1yHCWpA4ZzpLUIR/wug5VRdXBx7wmmWJrJM0yz5zXaeeeW9lx6S3TboakGeeZ83p5tixpAjxzlqQOGc6S1CHDWZI6ZDhLUocMZ0nqkOEsSR0ynCWpQ4azJHXIcJakDhnOktQhw1mSOmQ4S1KHDGdJ6tBUwjnJbyW5M8kdSa5McnSSU5LclmRfkk8kObLVPaqt72vbT55GmyVpkiYezkm2Ar8JbKuqFwCHAzuA9wIfqKrnAQ8D57e3nA883Mo/0OpJ0kybVrfGEcDPJjkCeApwP/BS4Oq2/Qrg1W35vLZO235OfASJpBk38XCuqvuA9wHfZhDKjwJfAB6pqsdatf3A1ra8Fbi3vfexVv8Zo5+bZHeSvUn2PvTQQ+PdCUkas2l0axzD4Gz4FOBZwFOB7U/2c6tqT1Vtq6ptxx133JP9OEmaqml0a/wy8M2qeqiqfgpcA5wNbGndHAAnAve15fuAkwDa9qcD35tskyVpsqYRzt8GzkjylNZ3fA5wF3Az8JpWZxdwbVu+rq3Ttn+mhh+BLUkzaBp9zrcxuLD3ReArrQ17gN8B3p5kH4M+5cvaWy4DntHK3w5cOOk2S9KkTeXp21V1MXDxSPE3gBctUfdvgddOol2S1AvvEJSkDhnOktQhw1mSOmQ4S1KHDGdJ6pDhLEkdMpwlqUOGsyR1yHCWpA5N5Q7Bza6qGJ3ewymmJW0kw/kQ7dxzKyRQxVVvOmvazZE0Y9bUrZHk7LWUzZVkcLbsGbOkMVhrn/PvrbFMkrQBVuzWSHImcBZwXJK3D236OQYPZpUkjcFqfc5HAk9r9f7eUPkPODgxviRpg60YzlX1F8BfJPloVX1rQm2SpLm31tEaRyXZA5w8/J6qeuk4GiVJ826t4fxHwH8DPgL83fiaI0mCtYfzY1V1yVhbIkk6YK1D6f40yb9LckKSYxdfY22ZJM2xtZ4572p///1QWQHP3djmSJJgjeFcVaeMuyGSpIPWFM5J3rBUeVV9bGObI0mCtXdr/OLQ8tHAOcAXgbkPZ2eokzQOa+3W+I3h9SRbgKvG0aDNyBnqJG20Q50y9G8A+6EXtRnqavWakrQma+1z/lM4kD2HA38f+OS4GiVJ826tZ87vG1p+DPhWVe0fQ3skSazxJpQ2AdJXGcxMdwzwk3E2SpLm3VqfhPI64HPAa4HXAbclccpQSRqTtXZrvAv4xap6ECDJccCfAVePq2GSNM/WOrfGYYvB3HxvHe+VJK3TWs+cr09yA3BlW/9XwKfH06SNsdTNIdP4Tm9IkXQoslKAJXkecHxV/d8k/xL4pbbpEeDjVfX18Tdx/Y59zvPrZe+8nFpYIIcdRhIWFhZIG4+81HJVrbh9zXXhcTekGM7SXNmw/+FXO3P+IHARQFVdA1wDkOQftm3/fKMastGSUNMIRm9IkbQBVus3Pr6qvjJa2MpOHkuLJEmrhvOWFbb97Aa2Q5I0ZLVw3pvk344WJvl14AvjaZIkabU+57cBf5Lk9RwM423AkcC/GGO7JGmurXjmXFXfqaqzgHcDf91e766qM6vqgUP90iRbklyd5KtJ7k5yZnsu4Y1J7ml/j2l1k+TDSfYluT3J6Yf6vZK0Wax1bo2bq+r32uszG/C9HwKur6rnA78A3A1cCNxUVacCN7V1gFcCp7bXbsCngEuaeRO/yy/J04F/AlwGUFU/qapHgPOAK1q1K4BXt+XzgI/VwGeBLUlOmGijJWnCpnEL9inAQ8AfJvlSko8keSqDYXv3tzoPAMe35a3AvUPv39/KHifJ7iR7k+z98Q8fGV/rJWkCphHORwCnA5dU1QsZPFXlwuEKNbhtcV33cVTVnqraVlXbjnralo1qqyRNxTTCeT+wv6pua+tXMwjr7yx2V7S/ixMt3QecNPT+E1uZJM2siYdzG+Vxb5Kfb0XnAHcB1wG7Wtku4Nq2fB3whjZq4wzg0aHuD0maSYf6gNcn6zeAjyc5EvgG8EYGPxSfTHI+8C0Gk/rDYPa7c4F9wI9aXUmaaVMJ56r6MoObWUads0TdAi4Yd5skqSdOmC9JHTKcJalDhrMkdchwlqQOGc6S1CHDWZI6ZDhLUocMZ0nqkOEsSR2a1u3bc2Vwk+NBSabUEkmbheE8JlV1IJSrip17bgXgqjedNc1mSdokDOcx2rnnVkiohQVymD1IktbOxBinZNCFYTeGpHUynCWpQ4azJHXIcJakDhnOktQhw1mSOmQ4S1KHDGdJ6pDhLEkdMpwlqUOGsyR1yHCWpA4ZzpLUIcNZkjpkOEtSh5zPeYKGJ+Bf5FNRJC3FcJ6wxQn4qfKpKJKWZThPWpuAv1avKWmO2ecsSR0ynCWpQ4azJHXIcJakDhnOktQhw1mSOmQ4S1KHDGdJ6tDUwjnJ4Um+lORTbf2UJLcl2ZfkE0mObOVHtfV9bfvJ02qzJE3KNM+c3wrcPbT+XuADVfU84GHg/FZ+PvBwK/9AqydJM20q4ZzkROCfAR9p6wFeClzdqlwBvLotn9fWadvPibMFSZpx0zpz/iDwDmChrT8DeKSqHmvr+4GtbXkrcC9A2/5oq/84SXYn2Ztk749/+Mj4Wi5JEzDxcE7yKuDBqvrCRn5uVe2pqm1Vte2op23ZyI+WpImbxqx0ZwO/kuRc4Gjg54APAVuSHNHOjk8E7mv17wNOAvYnOQJ4OvC9yTdbkiZn4mfOVXVRVZ1YVScDO4DPVNXrgZuB17Rqu4Br2/J1bZ22/TM1OmO9JM2YnsY5/w7w9iT7GPQpX9bKLwOe0crfDlw4pfZJ0sRMdbL9qvpz4M/b8jeAFy1R52+B1060YRPgI6skrcQnoUyRj6yStBzDeZp8ZJWkZfTU5yxJagxnSeqQ3Rod8OKgpFGGcye8OChpmOHcCy8OShpin7MkdchwlqQOGc6S1CHDWZI6ZDhLUocMZ0nqkEPpOjN6Q4o3o0jzyTPnDu3ccys7Lr1l2s2QNEWeOffIs2Vp7nnmLEkdMpwlqUOGsyR1yHCWpA4ZzpLUIcNZkjrkULpO+XQUab4Zzh3z6SjS/DKce+bTUaS5ZZ+zJHXIcJakDtmtscmMXiQELxRKs8hw3oR2XHqLFwqlGWc4b0ZeKJRmnuG8CQyPeV6qW0PS7DGcN4nFMc+1sEAO8zquNOv8v3yzaF0ZTsQvzQfPnDcxb/GWZpfhvMl5i7c0mwznzc6RG9JMss9ZkjpkOEtShyYezklOSnJzkruS3Jnkra382CQ3Jrmn/T2mlSfJh5PsS3J7ktMn3WZJmrRpnDk/Bvx2VZ0GnAFckOQ04ELgpqo6FbiprQO8Eji1vXYDl0y+yZI0WRMP56q6v6q+2Jb/H3A3sBU4D7iiVbsCeHVbPg/4WA18FtiS5ITJtlqSJmuqfc5JTgZeCNwGHF9V97dNDwDHt+WtwL1Db9vfykY/a3eSvUn2/viHj4ytzb1bHPs8/JK0+UxtKF2SpwF/DLytqn4wfPNEVVWSdaVKVe0B9gAc+5znz3UiLc5aVwsLTxj77E0q0uYwlXBO8jMMgvnjVXVNK/5OkhOq6v7WbfFgK78POGno7Se2Mi1ncexz4k0q0iY1jdEaAS4D7q6q9w9tug7Y1ZZ3AdcOlb+hjdo4A3h0qPtDq3FODmlTmsaZ89nArwJfSfLlVvZO4D3AJ5OcD3wLeF3b9mngXGAf8CPgjRNtrSRNwcTDuar+D7Dcadw5S9Qv4IKxNkqSOuPcGjPCkRnSbDGcZ8jOPbdSVU7GL80Aw3mWeNFPmhmG85xwYn5pczGc54hjnqXNw3CeJ07ML20aXjmSpA555jyHRidFGu57th9a6oPhPKcODLtbvLXbfmipK4bzvFo8Q7YfWuqSfc6S1CHDWZI6ZDhLUofsc9YTLDWBkqM4pMkynLWkxUddOYpDmg7DWUtzFIc0VfY5S1KHDGdJ6pDdGgIeP6WoT1SRps9w1gGLU4rWwsKKT1NxNIc0foazDlq8CDgUtMs9m9DRHNJ4Gc5a1ZKT9DuaQxorw1mrWyGIffyVNB6Gs9ZsuS6OlR5/Zf+0dGgMZ63LgXmghy8YLnFmPTzyw2cXSutnOGt9VjjrHR2ONxzkSViwC0RaM8NZG2q14XhLnUXb9SE9keGsjbXEcLwlt48UrzQ0z/DWPDKc1YdVhuY5rlrzxnDW5uC4as0Zw1lTsdxcHovli2VJnOtDc8lw1tQsd/HwwCiPZE1zfUizyHDW9Cx38XBxfY1zfWzExUEvOqo3hrM2neEz7qvedNaSXSDDwbpU18hSwXsoFx1XC3VDX4fKcNbmM3RGvWQXSFseDdkdl94CsHzwrjKHyOjyYuivdgfkYugv/piMfsbBrze0dZDhrM1tqS6QtrwwetFxJPyWCtxRS92GPvwDsNgfPvx9TziTH/kxWe1HZLn2GN7zxXDWTBu96LjULeajFx1Xuw19+AdgtL981YuZq/yIDKoMPvPJ3phjwG9uhrNm2xIhOhrIy4XsIY0UWeFi5koWQ/1x3R5rvDFnue6S1bpcxtVf7o/CxjCcNX/WEpzrDNeNaBMs/aOw7PMdV+kuWarL5eBbH392vlTAD7dnublQlhuPPnrRdrTuaDuejI34MejxB2XThHOS7cCHgMOBj1TVe6bcJGnjrdBdMhy+y07buoYulyXPzpcI+OVmFFyx/33kfav1sy8XimstX6kLaPQHbaURPKP7NDoKaPT7Ri1V98naFOGc5HDg94GXAfuBzye5rqrumm7LpAkZCd9D/QxYoctmle9Ytjtotbat0s++3Fn2SuXL/cgs9SMyeg1gue8Y/UFZ6X2D3Xr8vu649BY+8eazD+nQLCWb4dbYJGcC/6GqXtHWLwKoqv+yVP1jn/P8etk7L1/yV33FX/sx1PU7+vqO3tozz99BBkF3WA57XFkIC7WwYvkgkNded/R7l3rfavsx/L4khFAUV+0ehPbOPbfyiTefvWGnzpslnF8DbK+qX2/rvwq8uKreMlRnN7C7rb4AuGPiDZ28ZwLfnXYjxsx9nB3zsJ9HV9ULNuKDNkW3xlpU1R5gD0CSvVW1bcpNGrt52E/3cXbMw34m2btRn7VZZpO5DzhpaP3EViZJM2mzhPPngVOTnJLkSGAHcN2U2yRJY7MpujWq6rEkbwFuYDCU7vKqunOFt+yZTMumbh72032cHfOwnxu2j5vigqAkzZvN0q0hSXPFcJakDs1cOCfZnuRrSfYluXDa7TlUSU5KcnOSu5LcmeStrfzYJDcmuaf9PaaVJ8mH237fnuT06e7B2iU5PMmXknyqrZ+S5La2L59oF4FJclRb39e2nzzVhq9Dki1Jrk7y1SR3Jzlz1o5lkt9q/63ekeTKJEfPwrFMcnmSB5PcMVS27mOXZFerf0+SXat970yFcw7e5v1K4DRgZ5LTptuqQ/YY8NtVdRpwBnBB25cLgZuq6lTgprYOg30+tb12A5dMvsmH7K3A3UPr7wU+UFXPAx4Gzm/l5wMPt/IPtHqbxYeA66vq+cAvMNjfmTmWSbYCvwlsazdhHM5gVNUsHMuPAttHytZ17JIcC1wMvBh4EXDxYqAva3HGq1l4AWcCNwytXwRcNO12bdC+XctgbpGvASe0shOAr7XlS4GdQ/UP1Ov5xWDM+k3AS4FPAWFwF9kRo8eUwWidM9vyEa1epr0Pa9jHpwPfHG3rLB1LYCtwL3BsOzafAl4xK8cSOBm441CPHbATuHSo/HH1lnrN1JkzB/8DWbS/lW1q7Z98LwRuA46vqvvbpgeA49vyZt33DwLvABba+jOAR6rqsbY+vB8H9rFtf7TV790pwEPAH7bum48keSozdCyr6j7gfcC3gfsZHJsvMHvHctF6j926j+mshfPMSfI04I+Bt1XVD4a31eAneNOOhUzyKuDBqvrCtNsyZkcApwOXVNULgb/h4D+DgZk4lscA5zH4IXoW8FSe2BUwk8Z17GYtnGfqNu8kP8MgmD9eVde04u8kOaFtPwF4sJVvxn0/G/iVJH8NXMWga+NDwJYkizdIDe/HgX1s258OfG+SDT5E+4H9VXVbW7+aQVjP0rH8ZeCbVfVQVf0UuIbB8Z21Y7lovcdu3cd01sJ5Zm7zThLgMuDuqnr/0KbrgMUrvbsY9EUvlr+hXS0+A3h06J9dXaqqi6rqxKo6mcGx+kxVvR64GXhNqza6j4v7/ppWv/uzzap6ALg3yc+3onOAu5ihY8mgO+OMJE9p/+0u7uNMHcsh6z12NwAvT3JM+1fGy1vZ8qbd0T6Gjvtzgb8Cvg68a9rteRL78UsM/ql0O/Dl9jqXQb/cTcA9wJ8Bx7b6YTBS5evAVxhcNZ/6fqxjf18CfKotPxf4HLAP+CPgqFZ+dFvf17Y/d9rtXsf+/WNgbzue/xM4ZtaOJfBu4KsMpuv978BRs3AsgSsZ9KP/lMG/gs4/lGMH/Frb333AG1f7Xm/flqQOzVq3hiTNBMNZkjpkOEtShwxnSeqQ4SxJHTKcJalDhrMkdej/A79KBmTUaCbVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.displot(text_len)\n",
    "plt.xlim(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0800857-4916-41b9-bb88-5ae6024254cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   27,    63,     5, ...,     0,     0,     0],\n",
       "       [   47,   253, 34849, ...,     0,     0,     0],\n",
       "       [   20,     2,  2269, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [   36,     7,    77, ...,     0,     0,     0],\n",
       "       [ 6066,   352,   142, ...,     0,     0,     0],\n",
       "       [   15,     9,   279, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "pad_text = pad_sequences(text, maxlen = 300, padding = \"post\", truncating=\"post\")\n",
    "pad_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c4c25580-e13f-4349-a248-7df38a3eae5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   27,    63,     5, ...,     0,     0,     0],\n",
       "       [   47,   253, 34849, ...,     0,     0,     0],\n",
       "       [   20,     2,  2269, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 2247,     1,   186, ...,     0,     0,     0],\n",
       "       [   98,   157,    77, ...,     0,     0,     0],\n",
       "       [  265,    58,     4, ...,     0,     0,     0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[   1, 4697, 1114, ...,    0,    0,    0],\n",
       "       [1556,    8,    4, ...,    0,    0,    0],\n",
       "       [1615,    7, 2203, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  36,    7,   77, ...,    0,    0,    0],\n",
       "       [6066,  352,  142, ...,    0,    0,    0],\n",
       "       [  15,    9,  279, ...,    0,    0,    0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train2 = pad_text[:len(train)]\n",
    "test2 = pad_text[len(train):]\n",
    "display(train2, test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d05caeb-d6d0-458d-9961-50127892fae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 6ms/step - loss: 2.9814 - acc: 0.0666 - val_loss: 2.9537 - val_acc: 0.0736\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 2.9044 - acc: 0.0891 - val_loss: 2.8377 - val_acc: 0.1071\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 2.7290 - acc: 0.1270 - val_loss: 2.6265 - val_acc: 0.1623\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 2.5318 - acc: 0.1726 - val_loss: 2.4953 - val_acc: 0.1937\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.3822 - acc: 0.2119 - val_loss: 2.3803 - val_acc: 0.2219\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 2.2418 - acc: 0.2650 - val_loss: 2.2745 - val_acc: 0.3030\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.0900 - acc: 0.3333 - val_loss: 2.1479 - val_acc: 0.3452\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.9469 - acc: 0.3808 - val_loss: 2.0509 - val_acc: 0.3669\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8021 - acc: 0.4439 - val_loss: 1.9428 - val_acc: 0.4307\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.6650 - acc: 0.4979 - val_loss: 1.8425 - val_acc: 0.4524\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5290 - acc: 0.5440 - val_loss: 1.7553 - val_acc: 0.4762\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4090 - acc: 0.5937 - val_loss: 1.6786 - val_acc: 0.5141\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2892 - acc: 0.6337 - val_loss: 1.6112 - val_acc: 0.5238\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1865 - acc: 0.6731 - val_loss: 1.5509 - val_acc: 0.5411\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0853 - acc: 0.7092 - val_loss: 1.5003 - val_acc: 0.5617\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0028 - acc: 0.7382 - val_loss: 1.4663 - val_acc: 0.5671\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9188 - acc: 0.7619 - val_loss: 1.4277 - val_acc: 0.5758\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8468 - acc: 0.7831 - val_loss: 1.3939 - val_acc: 0.5714\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7823 - acc: 0.8080 - val_loss: 1.3698 - val_acc: 0.5866\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7184 - acc: 0.8310 - val_loss: 1.3534 - val_acc: 0.5909\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6663 - acc: 0.8472 - val_loss: 1.3392 - val_acc: 0.5974\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6125 - acc: 0.8629 - val_loss: 1.3287 - val_acc: 0.6028\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5683 - acc: 0.8768 - val_loss: 1.3379 - val_acc: 0.6028\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5234 - acc: 0.8880 - val_loss: 1.3376 - val_acc: 0.5931\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4876 - acc: 0.8990 - val_loss: 1.3201 - val_acc: 0.6126\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4524 - acc: 0.9084 - val_loss: 1.3187 - val_acc: 0.6158\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4204 - acc: 0.9200 - val_loss: 1.3261 - val_acc: 0.6104\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3876 - acc: 0.9267 - val_loss: 1.3436 - val_acc: 0.6212\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3621 - acc: 0.9337 - val_loss: 1.3442 - val_acc: 0.6093\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3379 - acc: 0.9366 - val_loss: 1.3655 - val_acc: 0.6180\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3165 - acc: 0.9434 - val_loss: 1.3735 - val_acc: 0.6050\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2954 - acc: 0.9487 - val_loss: 1.4093 - val_acc: 0.6093\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2734 - acc: 0.9551 - val_loss: 1.3990 - val_acc: 0.6115\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2563 - acc: 0.9594 - val_loss: 1.4213 - val_acc: 0.6082\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2400 - acc: 0.9602 - val_loss: 1.4399 - val_acc: 0.6169\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2269 - acc: 0.9606 - val_loss: 1.4636 - val_acc: 0.6104\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2130 - acc: 0.9656 - val_loss: 1.5006 - val_acc: 0.6136\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1989 - acc: 0.9675 - val_loss: 1.5008 - val_acc: 0.6115\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1897 - acc: 0.9682 - val_loss: 1.5931 - val_acc: 0.5963\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1824 - acc: 0.9693 - val_loss: 1.5555 - val_acc: 0.6190\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.1642 - acc: 0.9739 - val_loss: 1.5830 - val_acc: 0.6136\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1592 - acc: 0.9733 - val_loss: 1.6037 - val_acc: 0.6190\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1547 - acc: 0.9730 - val_loss: 1.6069 - val_acc: 0.6190\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1436 - acc: 0.9756 - val_loss: 1.6587 - val_acc: 0.6169\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1347 - acc: 0.9782 - val_loss: 1.6651 - val_acc: 0.6234\n",
      "Epoch 46/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1293 - acc: 0.9789 - val_loss: 1.7057 - val_acc: 0.6245\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9837 - acc: 0.0663 - val_loss: 2.9587 - val_acc: 0.0833\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9101 - acc: 0.0909 - val_loss: 2.8564 - val_acc: 0.1071\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.7287 - acc: 0.1331 - val_loss: 2.6422 - val_acc: 0.1580\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.5069 - acc: 0.1880 - val_loss: 2.4678 - val_acc: 0.2067\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.3113 - acc: 0.2497 - val_loss: 2.3169 - val_acc: 0.2392\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.1345 - acc: 0.3105 - val_loss: 2.1891 - val_acc: 0.2803\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.9760 - acc: 0.3704 - val_loss: 2.0791 - val_acc: 0.3312\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8236 - acc: 0.4329 - val_loss: 1.9870 - val_acc: 0.3755\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.6844 - acc: 0.4841 - val_loss: 1.9053 - val_acc: 0.4156\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5591 - acc: 0.5255 - val_loss: 1.8431 - val_acc: 0.4286\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4492 - acc: 0.5691 - val_loss: 1.7917 - val_acc: 0.4481\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.3396 - acc: 0.6138 - val_loss: 1.7348 - val_acc: 0.4665\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2384 - acc: 0.6578 - val_loss: 1.6978 - val_acc: 0.4827\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 1.1455 - acc: 0.6937 - val_loss: 1.6610 - val_acc: 0.5076\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 1.0577 - acc: 0.7251 - val_loss: 1.6260 - val_acc: 0.5195\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.9737 - acc: 0.7518 - val_loss: 1.6065 - val_acc: 0.5238\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.8985 - acc: 0.7840 - val_loss: 1.5849 - val_acc: 0.5400\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.8242 - acc: 0.8074 - val_loss: 1.5573 - val_acc: 0.5584\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7618 - acc: 0.8245 - val_loss: 1.5485 - val_acc: 0.5509\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7041 - acc: 0.8444 - val_loss: 1.5469 - val_acc: 0.5595\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6509 - acc: 0.8580 - val_loss: 1.5496 - val_acc: 0.5725\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5992 - acc: 0.8748 - val_loss: 1.5377 - val_acc: 0.5790\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5492 - acc: 0.8889 - val_loss: 1.5558 - val_acc: 0.5714\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5085 - acc: 0.9023 - val_loss: 1.5435 - val_acc: 0.5812\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4751 - acc: 0.9094 - val_loss: 1.5700 - val_acc: 0.5823\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4373 - acc: 0.9195 - val_loss: 1.5709 - val_acc: 0.5844\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4083 - acc: 0.9265 - val_loss: 1.5826 - val_acc: 0.5920\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3781 - acc: 0.9344 - val_loss: 1.6132 - val_acc: 0.5898\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3524 - acc: 0.9432 - val_loss: 1.6293 - val_acc: 0.5898\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3317 - acc: 0.9426 - val_loss: 1.6360 - val_acc: 0.5887\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3064 - acc: 0.9487 - val_loss: 1.6696 - val_acc: 0.5963\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2874 - acc: 0.9532 - val_loss: 1.6859 - val_acc: 0.5974\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2698 - acc: 0.9550 - val_loss: 1.6985 - val_acc: 0.5963\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2555 - acc: 0.9561 - val_loss: 1.7209 - val_acc: 0.6017\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2350 - acc: 0.9623 - val_loss: 1.7605 - val_acc: 0.5963\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2220 - acc: 0.9671 - val_loss: 1.7596 - val_acc: 0.5985\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2084 - acc: 0.9657 - val_loss: 1.7739 - val_acc: 0.6147\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1981 - acc: 0.9697 - val_loss: 1.8103 - val_acc: 0.6071\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1864 - acc: 0.9702 - val_loss: 1.8398 - val_acc: 0.6017\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1767 - acc: 0.9711 - val_loss: 1.8652 - val_acc: 0.6180\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1682 - acc: 0.9736 - val_loss: 1.8968 - val_acc: 0.6115\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1595 - acc: 0.9721 - val_loss: 1.9215 - val_acc: 0.6039\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9836 - acc: 0.0705 - val_loss: 2.9588 - val_acc: 0.0801\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9034 - acc: 0.0927 - val_loss: 2.8390 - val_acc: 0.1093\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.7191 - acc: 0.1244 - val_loss: 2.6496 - val_acc: 0.1288\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.5456 - acc: 0.1591 - val_loss: 2.5303 - val_acc: 0.1840\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.4206 - acc: 0.2035 - val_loss: 2.4439 - val_acc: 0.2013\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.2947 - acc: 0.2444 - val_loss: 2.3293 - val_acc: 0.2457\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.1568 - acc: 0.3004 - val_loss: 2.2112 - val_acc: 0.2868\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.0096 - acc: 0.3668 - val_loss: 2.0989 - val_acc: 0.3268\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8597 - acc: 0.4341 - val_loss: 1.9958 - val_acc: 0.3701\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.7206 - acc: 0.4816 - val_loss: 1.8996 - val_acc: 0.4134\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5851 - acc: 0.5320 - val_loss: 1.8115 - val_acc: 0.4491\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4606 - acc: 0.5821 - val_loss: 1.7339 - val_acc: 0.4632\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.3458 - acc: 0.6232 - val_loss: 1.6622 - val_acc: 0.4903\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2337 - acc: 0.6693 - val_loss: 1.6099 - val_acc: 0.5054\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1349 - acc: 0.7035 - val_loss: 1.5647 - val_acc: 0.5076\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0365 - acc: 0.7398 - val_loss: 1.5077 - val_acc: 0.5379\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9500 - acc: 0.7668 - val_loss: 1.4733 - val_acc: 0.5422\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8644 - acc: 0.7958 - val_loss: 1.4448 - val_acc: 0.5693\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7918 - acc: 0.8168 - val_loss: 1.4109 - val_acc: 0.5758\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7228 - acc: 0.8402 - val_loss: 1.3866 - val_acc: 0.5823\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6642 - acc: 0.8592 - val_loss: 1.3787 - val_acc: 0.5963\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6078 - acc: 0.8706 - val_loss: 1.3657 - val_acc: 0.6039\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5602 - acc: 0.8829 - val_loss: 1.3689 - val_acc: 0.5963\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5174 - acc: 0.8937 - val_loss: 1.3741 - val_acc: 0.6017\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4765 - acc: 0.9043 - val_loss: 1.3552 - val_acc: 0.6169\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4409 - acc: 0.9143 - val_loss: 1.3598 - val_acc: 0.6136\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4089 - acc: 0.9224 - val_loss: 1.3786 - val_acc: 0.6126\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3810 - acc: 0.9283 - val_loss: 1.3751 - val_acc: 0.6180\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3535 - acc: 0.9334 - val_loss: 1.3843 - val_acc: 0.6266\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3279 - acc: 0.9434 - val_loss: 1.3960 - val_acc: 0.6266\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.3069 - acc: 0.9466 - val_loss: 1.4085 - val_acc: 0.6320\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2847 - acc: 0.9507 - val_loss: 1.4270 - val_acc: 0.6342\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2709 - acc: 0.9525 - val_loss: 1.4905 - val_acc: 0.6212\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2498 - acc: 0.9604 - val_loss: 1.4676 - val_acc: 0.6310\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.2342 - acc: 0.9638 - val_loss: 1.4988 - val_acc: 0.6288\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2195 - acc: 0.9656 - val_loss: 1.5001 - val_acc: 0.6320\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2069 - acc: 0.9661 - val_loss: 1.5265 - val_acc: 0.6385\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.1975 - acc: 0.9674 - val_loss: 1.5453 - val_acc: 0.6320\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.1866 - acc: 0.9680 - val_loss: 1.5639 - val_acc: 0.6418\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.1754 - acc: 0.9722 - val_loss: 1.5891 - val_acc: 0.6299\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1635 - acc: 0.9733 - val_loss: 1.6466 - val_acc: 0.6288\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1572 - acc: 0.9752 - val_loss: 1.6458 - val_acc: 0.6277\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1494 - acc: 0.9741 - val_loss: 1.6706 - val_acc: 0.6277\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1417 - acc: 0.9783 - val_loss: 1.7068 - val_acc: 0.6331\n",
      "Epoch 45/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1354 - acc: 0.9773 - val_loss: 1.6935 - val_acc: 0.6310\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 2.9844 - acc: 0.0700 - val_loss: 2.9522 - val_acc: 0.0823\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9077 - acc: 0.0942 - val_loss: 2.8443 - val_acc: 0.1094\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.7238 - acc: 0.1301 - val_loss: 2.6418 - val_acc: 0.1528\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.5184 - acc: 0.1746 - val_loss: 2.4926 - val_acc: 0.1788\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.3602 - acc: 0.2138 - val_loss: 2.3740 - val_acc: 0.2340\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.2103 - acc: 0.2817 - val_loss: 2.2598 - val_acc: 0.2947\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.0404 - acc: 0.3609 - val_loss: 2.1370 - val_acc: 0.3489\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8683 - acc: 0.4177 - val_loss: 2.0110 - val_acc: 0.3857\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.7141 - acc: 0.4696 - val_loss: 1.9186 - val_acc: 0.4182\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5703 - acc: 0.5225 - val_loss: 1.8210 - val_acc: 0.4550\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4479 - acc: 0.5621 - val_loss: 1.7513 - val_acc: 0.4702\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.3318 - acc: 0.6090 - val_loss: 1.6986 - val_acc: 0.4745\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2339 - acc: 0.6458 - val_loss: 1.6312 - val_acc: 0.5103\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1386 - acc: 0.6847 - val_loss: 1.5838 - val_acc: 0.5179\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0496 - acc: 0.7231 - val_loss: 1.5416 - val_acc: 0.5395\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9668 - acc: 0.7492 - val_loss: 1.5068 - val_acc: 0.5655\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8897 - acc: 0.7877 - val_loss: 1.4794 - val_acc: 0.5558\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.8185 - acc: 0.8051 - val_loss: 1.4539 - val_acc: 0.5623\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7500 - acc: 0.8319 - val_loss: 1.4383 - val_acc: 0.5796\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6857 - acc: 0.8517 - val_loss: 1.4175 - val_acc: 0.5980\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6310 - acc: 0.8692 - val_loss: 1.4053 - val_acc: 0.5894\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5819 - acc: 0.8804 - val_loss: 1.4160 - val_acc: 0.5883\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5341 - acc: 0.8943 - val_loss: 1.3951 - val_acc: 0.5980\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4875 - acc: 0.9001 - val_loss: 1.4076 - val_acc: 0.6078\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.4550 - acc: 0.9154 - val_loss: 1.3969 - val_acc: 0.6111\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.4200 - acc: 0.9213 - val_loss: 1.4051 - val_acc: 0.6121\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.3876 - acc: 0.9296 - val_loss: 1.4139 - val_acc: 0.6121\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3603 - acc: 0.9362 - val_loss: 1.4252 - val_acc: 0.6186\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3337 - acc: 0.9414 - val_loss: 1.4308 - val_acc: 0.6132\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3088 - acc: 0.9469 - val_loss: 1.4360 - val_acc: 0.6273\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2879 - acc: 0.9511 - val_loss: 1.4681 - val_acc: 0.6219\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2689 - acc: 0.9557 - val_loss: 1.4808 - val_acc: 0.6132\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2499 - acc: 0.9592 - val_loss: 1.4968 - val_acc: 0.6262\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2355 - acc: 0.9603 - val_loss: 1.5204 - val_acc: 0.6230\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2198 - acc: 0.9655 - val_loss: 1.5413 - val_acc: 0.6251\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2045 - acc: 0.9669 - val_loss: 1.5774 - val_acc: 0.6219\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1951 - acc: 0.9685 - val_loss: 1.6185 - val_acc: 0.6197\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1831 - acc: 0.9708 - val_loss: 1.6175 - val_acc: 0.6284\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1715 - acc: 0.9739 - val_loss: 1.6743 - val_acc: 0.6176\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1655 - acc: 0.9711 - val_loss: 1.6565 - val_acc: 0.6284\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1546 - acc: 0.9755 - val_loss: 1.7107 - val_acc: 0.6143\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1432 - acc: 0.9758 - val_loss: 1.7632 - val_acc: 0.6165\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1399 - acc: 0.9765 - val_loss: 1.7831 - val_acc: 0.6186\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9843 - acc: 0.0664 - val_loss: 2.9592 - val_acc: 0.0726\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9092 - acc: 0.0883 - val_loss: 2.8568 - val_acc: 0.1062\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.7293 - acc: 0.1307 - val_loss: 2.6244 - val_acc: 0.1712\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.5014 - acc: 0.2022 - val_loss: 2.4246 - val_acc: 0.2275\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.2922 - acc: 0.2580 - val_loss: 2.2555 - val_acc: 0.2481\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.1004 - acc: 0.3211 - val_loss: 2.1129 - val_acc: 0.3055\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.9284 - acc: 0.3807 - val_loss: 1.9840 - val_acc: 0.3532\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.7789 - acc: 0.4300 - val_loss: 1.8864 - val_acc: 0.3857\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.6412 - acc: 0.4774 - val_loss: 1.8150 - val_acc: 0.4030\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5243 - acc: 0.5280 - val_loss: 1.7372 - val_acc: 0.4193\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4188 - acc: 0.5665 - val_loss: 1.6812 - val_acc: 0.4496\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.3221 - acc: 0.5977 - val_loss: 1.6539 - val_acc: 0.4550\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2292 - acc: 0.6391 - val_loss: 1.5931 - val_acc: 0.4659\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1438 - acc: 0.6708 - val_loss: 1.5886 - val_acc: 0.4735\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0639 - acc: 0.7034 - val_loss: 1.5359 - val_acc: 0.4951\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9872 - acc: 0.7355 - val_loss: 1.5030 - val_acc: 0.5114\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9235 - acc: 0.7619 - val_loss: 1.4887 - val_acc: 0.5135\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8542 - acc: 0.7869 - val_loss: 1.4698 - val_acc: 0.5298\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7960 - acc: 0.8037 - val_loss: 1.4797 - val_acc: 0.5309\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7419 - acc: 0.8229 - val_loss: 1.4595 - val_acc: 0.5385\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6908 - acc: 0.8377 - val_loss: 1.4560 - val_acc: 0.5482\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6427 - acc: 0.8520 - val_loss: 1.4501 - val_acc: 0.5482\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5999 - acc: 0.8606 - val_loss: 1.4594 - val_acc: 0.5547\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5588 - acc: 0.8775 - val_loss: 1.4595 - val_acc: 0.5580\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5186 - acc: 0.8903 - val_loss: 1.4975 - val_acc: 0.5601\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4901 - acc: 0.8928 - val_loss: 1.5059 - val_acc: 0.5504\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4561 - acc: 0.9060 - val_loss: 1.5067 - val_acc: 0.5645\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4236 - acc: 0.9152 - val_loss: 1.5150 - val_acc: 0.5688\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3987 - acc: 0.9193 - val_loss: 1.5375 - val_acc: 0.5655\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.3686 - acc: 0.9333 - val_loss: 1.5797 - val_acc: 0.5710\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3419 - acc: 0.9392 - val_loss: 1.5952 - val_acc: 0.5677\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3262 - acc: 0.9418 - val_loss: 1.6262 - val_acc: 0.5796\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3022 - acc: 0.9489 - val_loss: 1.6373 - val_acc: 0.5753\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.2873 - acc: 0.9519 - val_loss: 1.6727 - val_acc: 0.5807\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.2651 - acc: 0.9575 - val_loss: 1.7071 - val_acc: 0.5861\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2501 - acc: 0.9590 - val_loss: 1.7311 - val_acc: 0.5753\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2362 - acc: 0.9638 - val_loss: 1.7582 - val_acc: 0.5807\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2210 - acc: 0.9664 - val_loss: 1.7962 - val_acc: 0.5818\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2167 - acc: 0.9614 - val_loss: 1.8271 - val_acc: 0.5775\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2015 - acc: 0.9679 - val_loss: 1.8538 - val_acc: 0.5764\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1903 - acc: 0.9711 - val_loss: 1.8870 - val_acc: 0.5753\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1786 - acc: 0.9740 - val_loss: 1.9295 - val_acc: 0.5796\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 2.9833 - acc: 0.0628 - val_loss: 2.9593 - val_acc: 0.0823\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9048 - acc: 0.0945 - val_loss: 2.8525 - val_acc: 0.1062\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.7318 - acc: 0.1467 - val_loss: 2.6208 - val_acc: 0.1820\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.4927 - acc: 0.2291 - val_loss: 2.4130 - val_acc: 0.2741\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.2682 - acc: 0.2948 - val_loss: 2.2294 - val_acc: 0.3196\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.0547 - acc: 0.3591 - val_loss: 2.0706 - val_acc: 0.3792\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8584 - acc: 0.4218 - val_loss: 1.9312 - val_acc: 0.4106\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.6912 - acc: 0.4788 - val_loss: 1.8161 - val_acc: 0.4529\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5412 - acc: 0.5277 - val_loss: 1.7125 - val_acc: 0.4875\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4091 - acc: 0.5868 - val_loss: 1.6351 - val_acc: 0.5222\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2874 - acc: 0.6367 - val_loss: 1.5759 - val_acc: 0.5406\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1755 - acc: 0.6863 - val_loss: 1.5058 - val_acc: 0.5558\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0794 - acc: 0.7190 - val_loss: 1.4603 - val_acc: 0.5699\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9852 - acc: 0.7474 - val_loss: 1.4204 - val_acc: 0.5742\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9026 - acc: 0.7803 - val_loss: 1.3887 - val_acc: 0.5807\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8295 - acc: 0.8024 - val_loss: 1.3617 - val_acc: 0.5915\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7598 - acc: 0.8298 - val_loss: 1.3476 - val_acc: 0.5872\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7035 - acc: 0.8449 - val_loss: 1.3318 - val_acc: 0.6046\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6478 - acc: 0.8613 - val_loss: 1.3212 - val_acc: 0.6046\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5992 - acc: 0.8748 - val_loss: 1.3306 - val_acc: 0.5926\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5527 - acc: 0.8865 - val_loss: 1.3222 - val_acc: 0.6100\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5131 - acc: 0.8978 - val_loss: 1.3195 - val_acc: 0.6186\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4736 - acc: 0.9087 - val_loss: 1.3251 - val_acc: 0.6165\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4395 - acc: 0.9189 - val_loss: 1.3406 - val_acc: 0.6143\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4133 - acc: 0.9199 - val_loss: 1.3387 - val_acc: 0.6219\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3845 - acc: 0.9300 - val_loss: 1.3466 - val_acc: 0.6176\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3561 - acc: 0.9354 - val_loss: 1.3705 - val_acc: 0.6197\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3325 - acc: 0.9430 - val_loss: 1.3756 - val_acc: 0.6219\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3141 - acc: 0.9462 - val_loss: 1.3940 - val_acc: 0.6284\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2901 - acc: 0.9498 - val_loss: 1.4140 - val_acc: 0.6241\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2723 - acc: 0.9539 - val_loss: 1.4425 - val_acc: 0.6132\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2573 - acc: 0.9566 - val_loss: 1.4550 - val_acc: 0.6165\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2387 - acc: 0.9598 - val_loss: 1.5156 - val_acc: 0.6132\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2277 - acc: 0.9600 - val_loss: 1.5085 - val_acc: 0.6154\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2137 - acc: 0.9629 - val_loss: 1.5336 - val_acc: 0.6251\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1984 - acc: 0.9671 - val_loss: 1.5493 - val_acc: 0.6186\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1898 - acc: 0.9699 - val_loss: 1.5681 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1781 - acc: 0.9706 - val_loss: 1.5958 - val_acc: 0.6186\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1709 - acc: 0.9709 - val_loss: 1.6333 - val_acc: 0.6197\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1623 - acc: 0.9742 - val_loss: 1.6555 - val_acc: 0.6132\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1517 - acc: 0.9761 - val_loss: 1.6927 - val_acc: 0.6100\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1447 - acc: 0.9753 - val_loss: 1.7051 - val_acc: 0.6143\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9800 - acc: 0.0684 - val_loss: 2.9533 - val_acc: 0.0737\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9030 - acc: 0.0936 - val_loss: 2.8355 - val_acc: 0.1138\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.7327 - acc: 0.1312 - val_loss: 2.6071 - val_acc: 0.1863\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.5385 - acc: 0.1755 - val_loss: 2.4514 - val_acc: 0.2134\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.3682 - acc: 0.2329 - val_loss: 2.3034 - val_acc: 0.2535\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.1905 - acc: 0.2857 - val_loss: 2.1562 - val_acc: 0.3229\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.0265 - acc: 0.3475 - val_loss: 2.0300 - val_acc: 0.3597\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8768 - acc: 0.3910 - val_loss: 1.9190 - val_acc: 0.4063\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.7363 - acc: 0.4422 - val_loss: 1.8240 - val_acc: 0.4323\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.6082 - acc: 0.4874 - val_loss: 1.7442 - val_acc: 0.4550\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4921 - acc: 0.5445 - val_loss: 1.6737 - val_acc: 0.4648\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.3864 - acc: 0.5783 - val_loss: 1.6164 - val_acc: 0.5016\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2861 - acc: 0.6227 - val_loss: 1.5809 - val_acc: 0.4940\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1970 - acc: 0.6604 - val_loss: 1.5320 - val_acc: 0.5200\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1054 - acc: 0.6958 - val_loss: 1.4875 - val_acc: 0.5352\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0292 - acc: 0.7266 - val_loss: 1.4591 - val_acc: 0.5515\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9523 - acc: 0.7560 - val_loss: 1.4360 - val_acc: 0.5536\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8807 - acc: 0.7875 - val_loss: 1.4093 - val_acc: 0.5677\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8189 - acc: 0.8047 - val_loss: 1.3901 - val_acc: 0.5699\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7617 - acc: 0.8230 - val_loss: 1.3784 - val_acc: 0.5731\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7057 - acc: 0.8381 - val_loss: 1.3764 - val_acc: 0.5720\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6521 - acc: 0.8519 - val_loss: 1.3653 - val_acc: 0.5861\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6048 - acc: 0.8736 - val_loss: 1.3538 - val_acc: 0.5872\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5638 - acc: 0.8782 - val_loss: 1.3625 - val_acc: 0.5840\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5218 - acc: 0.8975 - val_loss: 1.3563 - val_acc: 0.6035\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4840 - acc: 0.9028 - val_loss: 1.3583 - val_acc: 0.6056\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4442 - acc: 0.9194 - val_loss: 1.3683 - val_acc: 0.5959\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4182 - acc: 0.9252 - val_loss: 1.3879 - val_acc: 0.6002\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3900 - acc: 0.9266 - val_loss: 1.3955 - val_acc: 0.6002\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3643 - acc: 0.9354 - val_loss: 1.4156 - val_acc: 0.6067\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3385 - acc: 0.9420 - val_loss: 1.4246 - val_acc: 0.6067\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3159 - acc: 0.9465 - val_loss: 1.4318 - val_acc: 0.6100\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2933 - acc: 0.9514 - val_loss: 1.4453 - val_acc: 0.6251\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2754 - acc: 0.9544 - val_loss: 1.4838 - val_acc: 0.6165\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2583 - acc: 0.9558 - val_loss: 1.5030 - val_acc: 0.6176\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2411 - acc: 0.9620 - val_loss: 1.5090 - val_acc: 0.6165\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2245 - acc: 0.9634 - val_loss: 1.5262 - val_acc: 0.6197\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2148 - acc: 0.9650 - val_loss: 1.5529 - val_acc: 0.6208\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2015 - acc: 0.9690 - val_loss: 1.5756 - val_acc: 0.6176\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1900 - acc: 0.9702 - val_loss: 1.6133 - val_acc: 0.6241\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1781 - acc: 0.9723 - val_loss: 1.6266 - val_acc: 0.6349\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1671 - acc: 0.9730 - val_loss: 1.6714 - val_acc: 0.6154\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1576 - acc: 0.9753 - val_loss: 1.6985 - val_acc: 0.6176\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 2.9848 - acc: 0.0669 - val_loss: 2.9588 - val_acc: 0.0899\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9048 - acc: 0.0993 - val_loss: 2.8325 - val_acc: 0.1083\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.7113 - acc: 0.1385 - val_loss: 2.6269 - val_acc: 0.1495\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.5040 - acc: 0.1917 - val_loss: 2.4579 - val_acc: 0.2199\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.3192 - acc: 0.2446 - val_loss: 2.3068 - val_acc: 0.2741\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.1488 - acc: 0.3136 - val_loss: 2.1634 - val_acc: 0.3034\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.9871 - acc: 0.3723 - val_loss: 2.0417 - val_acc: 0.3445\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8383 - acc: 0.4242 - val_loss: 1.9476 - val_acc: 0.3532\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.7048 - acc: 0.4680 - val_loss: 1.8723 - val_acc: 0.3814\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5789 - acc: 0.5105 - val_loss: 1.7934 - val_acc: 0.4258\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4657 - acc: 0.5645 - val_loss: 1.7345 - val_acc: 0.4377\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.3572 - acc: 0.6032 - val_loss: 1.6755 - val_acc: 0.4713\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2580 - acc: 0.6426 - val_loss: 1.6358 - val_acc: 0.4875\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1630 - acc: 0.6756 - val_loss: 1.5924 - val_acc: 0.5049\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0760 - acc: 0.7090 - val_loss: 1.5536 - val_acc: 0.5200\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9915 - acc: 0.7450 - val_loss: 1.5177 - val_acc: 0.5330\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9178 - acc: 0.7646 - val_loss: 1.4874 - val_acc: 0.5417\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8502 - acc: 0.7905 - val_loss: 1.4715 - val_acc: 0.5536\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7813 - acc: 0.8149 - val_loss: 1.4483 - val_acc: 0.5504\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7272 - acc: 0.8307 - val_loss: 1.4476 - val_acc: 0.5655\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6713 - acc: 0.8487 - val_loss: 1.4196 - val_acc: 0.5796\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6167 - acc: 0.8692 - val_loss: 1.4399 - val_acc: 0.5807\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5734 - acc: 0.8770 - val_loss: 1.4355 - val_acc: 0.5710\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5343 - acc: 0.8897 - val_loss: 1.4127 - val_acc: 0.5926\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4927 - acc: 0.9012 - val_loss: 1.4183 - val_acc: 0.6035\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4621 - acc: 0.9088 - val_loss: 1.4483 - val_acc: 0.5926\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4258 - acc: 0.9189 - val_loss: 1.4363 - val_acc: 0.5926\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3956 - acc: 0.9259 - val_loss: 1.4627 - val_acc: 0.5894\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3714 - acc: 0.9307 - val_loss: 1.4726 - val_acc: 0.5970\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3450 - acc: 0.9400 - val_loss: 1.4978 - val_acc: 0.6002\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3226 - acc: 0.9437 - val_loss: 1.5104 - val_acc: 0.6067\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3037 - acc: 0.9474 - val_loss: 1.5010 - val_acc: 0.6067\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2844 - acc: 0.9515 - val_loss: 1.5316 - val_acc: 0.6111\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2662 - acc: 0.9578 - val_loss: 1.5434 - val_acc: 0.6089\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2525 - acc: 0.9584 - val_loss: 1.5637 - val_acc: 0.6154\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2365 - acc: 0.9619 - val_loss: 1.5994 - val_acc: 0.6230\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2222 - acc: 0.9655 - val_loss: 1.6136 - val_acc: 0.6186\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2098 - acc: 0.9649 - val_loss: 1.6310 - val_acc: 0.6241\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1982 - acc: 0.9694 - val_loss: 1.6842 - val_acc: 0.6132\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1911 - acc: 0.9677 - val_loss: 1.6906 - val_acc: 0.6295\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1776 - acc: 0.9721 - val_loss: 1.7178 - val_acc: 0.6241\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1674 - acc: 0.9746 - val_loss: 1.7440 - val_acc: 0.6197\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1607 - acc: 0.9751 - val_loss: 1.7617 - val_acc: 0.6197\n",
      "Epoch 44/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1489 - acc: 0.9786 - val_loss: 1.7907 - val_acc: 0.6295\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 2.9812 - acc: 0.0712 - val_loss: 2.9504 - val_acc: 0.0802\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.8913 - acc: 0.0984 - val_loss: 2.8246 - val_acc: 0.0986\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.6940 - acc: 0.1395 - val_loss: 2.6113 - val_acc: 0.1549\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.4996 - acc: 0.1823 - val_loss: 2.4652 - val_acc: 0.1874\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.3289 - acc: 0.2426 - val_loss: 2.3260 - val_acc: 0.2589\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.1620 - acc: 0.2912 - val_loss: 2.1983 - val_acc: 0.2795\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.0012 - acc: 0.3563 - val_loss: 2.0886 - val_acc: 0.3283\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8569 - acc: 0.4045 - val_loss: 1.9921 - val_acc: 0.3846\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.7199 - acc: 0.4613 - val_loss: 1.9044 - val_acc: 0.4171\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5955 - acc: 0.5034 - val_loss: 1.8319 - val_acc: 0.4312\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4801 - acc: 0.5467 - val_loss: 1.7737 - val_acc: 0.4442\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.3766 - acc: 0.5817 - val_loss: 1.7402 - val_acc: 0.4410\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2770 - acc: 0.6295 - val_loss: 1.6900 - val_acc: 0.4615\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1883 - acc: 0.6637 - val_loss: 1.6378 - val_acc: 0.4897\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1005 - acc: 0.6922 - val_loss: 1.6059 - val_acc: 0.5060\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0227 - acc: 0.7300 - val_loss: 1.5771 - val_acc: 0.5211\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9470 - acc: 0.7557 - val_loss: 1.5553 - val_acc: 0.5320\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8765 - acc: 0.7801 - val_loss: 1.5221 - val_acc: 0.5450\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8082 - acc: 0.8067 - val_loss: 1.5180 - val_acc: 0.5428\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7513 - acc: 0.8258 - val_loss: 1.4917 - val_acc: 0.5623\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6938 - acc: 0.8412 - val_loss: 1.4950 - val_acc: 0.5601\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6427 - acc: 0.8599 - val_loss: 1.4968 - val_acc: 0.5612\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5967 - acc: 0.8721 - val_loss: 1.4832 - val_acc: 0.5655\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5506 - acc: 0.8906 - val_loss: 1.5048 - val_acc: 0.5601\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5106 - acc: 0.9005 - val_loss: 1.4967 - val_acc: 0.5688\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4733 - acc: 0.9096 - val_loss: 1.5066 - val_acc: 0.5753\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4376 - acc: 0.9221 - val_loss: 1.4956 - val_acc: 0.5926\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4095 - acc: 0.9266 - val_loss: 1.5296 - val_acc: 0.5785\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3807 - acc: 0.9341 - val_loss: 1.5308 - val_acc: 0.5883\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3537 - acc: 0.9383 - val_loss: 1.5393 - val_acc: 0.5959\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3291 - acc: 0.9465 - val_loss: 1.5640 - val_acc: 0.5959\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3073 - acc: 0.9469 - val_loss: 1.5733 - val_acc: 0.5905\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2875 - acc: 0.9539 - val_loss: 1.6232 - val_acc: 0.5731\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2695 - acc: 0.9576 - val_loss: 1.6153 - val_acc: 0.5937\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2528 - acc: 0.9600 - val_loss: 1.6396 - val_acc: 0.5948\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2386 - acc: 0.9619 - val_loss: 1.6936 - val_acc: 0.5915\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.2229 - acc: 0.9663 - val_loss: 1.6947 - val_acc: 0.5948\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2100 - acc: 0.9664 - val_loss: 1.7328 - val_acc: 0.5796\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 0s 4ms/step - loss: 0.1982 - acc: 0.9709 - val_loss: 1.7543 - val_acc: 0.5818\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1865 - acc: 0.9714 - val_loss: 1.7865 - val_acc: 0.5915\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1779 - acc: 0.9732 - val_loss: 1.8250 - val_acc: 0.5861\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1686 - acc: 0.9744 - val_loss: 1.8393 - val_acc: 0.5850\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1596 - acc: 0.9752 - val_loss: 1.8657 - val_acc: 0.5937\n",
      "Epoch 1/100\n",
      "130/130 [==============================] - 1s 5ms/step - loss: 2.9835 - acc: 0.0643 - val_loss: 2.9482 - val_acc: 0.0834\n",
      "Epoch 2/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.9080 - acc: 0.0924 - val_loss: 2.8281 - val_acc: 0.1159\n",
      "Epoch 3/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.7217 - acc: 0.1327 - val_loss: 2.6210 - val_acc: 0.1506\n",
      "Epoch 4/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.5134 - acc: 0.1858 - val_loss: 2.4767 - val_acc: 0.2124\n",
      "Epoch 5/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.3399 - acc: 0.2313 - val_loss: 2.3546 - val_acc: 0.2373\n",
      "Epoch 6/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.1834 - acc: 0.2835 - val_loss: 2.2368 - val_acc: 0.2882\n",
      "Epoch 7/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 2.0370 - acc: 0.3452 - val_loss: 2.1283 - val_acc: 0.3489\n",
      "Epoch 8/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.8861 - acc: 0.4126 - val_loss: 2.0274 - val_acc: 0.3694\n",
      "Epoch 9/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.7422 - acc: 0.4700 - val_loss: 1.9182 - val_acc: 0.3998\n",
      "Epoch 10/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.5935 - acc: 0.5301 - val_loss: 1.8259 - val_acc: 0.4355\n",
      "Epoch 11/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.4607 - acc: 0.5797 - val_loss: 1.7425 - val_acc: 0.4800\n",
      "Epoch 12/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.3378 - acc: 0.6212 - val_loss: 1.6874 - val_acc: 0.4897\n",
      "Epoch 13/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.2194 - acc: 0.6765 - val_loss: 1.6155 - val_acc: 0.5060\n",
      "Epoch 14/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.1158 - acc: 0.7049 - val_loss: 1.5609 - val_acc: 0.5352\n",
      "Epoch 15/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 1.0201 - acc: 0.7446 - val_loss: 1.5184 - val_acc: 0.5406\n",
      "Epoch 16/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.9286 - acc: 0.7757 - val_loss: 1.4835 - val_acc: 0.5482\n",
      "Epoch 17/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.8492 - acc: 0.8007 - val_loss: 1.4565 - val_acc: 0.5601\n",
      "Epoch 18/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7801 - acc: 0.8203 - val_loss: 1.4379 - val_acc: 0.5601\n",
      "Epoch 19/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.7126 - acc: 0.8456 - val_loss: 1.4371 - val_acc: 0.5666\n",
      "Epoch 20/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.6498 - acc: 0.8609 - val_loss: 1.4141 - val_acc: 0.5742\n",
      "Epoch 21/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5997 - acc: 0.8811 - val_loss: 1.4141 - val_acc: 0.5915\n",
      "Epoch 22/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5485 - acc: 0.8935 - val_loss: 1.4191 - val_acc: 0.5980\n",
      "Epoch 23/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.5023 - acc: 0.9055 - val_loss: 1.4117 - val_acc: 0.6013\n",
      "Epoch 24/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4635 - acc: 0.9123 - val_loss: 1.4170 - val_acc: 0.6056\n",
      "Epoch 25/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.4271 - acc: 0.9221 - val_loss: 1.4437 - val_acc: 0.6013\n",
      "Epoch 26/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3976 - acc: 0.9286 - val_loss: 1.4391 - val_acc: 0.6100\n",
      "Epoch 27/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3674 - acc: 0.9355 - val_loss: 1.4724 - val_acc: 0.6002\n",
      "Epoch 28/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3384 - acc: 0.9406 - val_loss: 1.4787 - val_acc: 0.6111\n",
      "Epoch 29/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.3150 - acc: 0.9439 - val_loss: 1.5097 - val_acc: 0.6176\n",
      "Epoch 30/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2925 - acc: 0.9513 - val_loss: 1.5307 - val_acc: 0.6089\n",
      "Epoch 31/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2719 - acc: 0.9542 - val_loss: 1.5364 - val_acc: 0.6067\n",
      "Epoch 32/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2552 - acc: 0.9579 - val_loss: 1.5593 - val_acc: 0.6078\n",
      "Epoch 33/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2353 - acc: 0.9604 - val_loss: 1.5908 - val_acc: 0.6176\n",
      "Epoch 34/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2215 - acc: 0.9640 - val_loss: 1.6241 - val_acc: 0.6143\n",
      "Epoch 35/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.2065 - acc: 0.9674 - val_loss: 1.6577 - val_acc: 0.6100\n",
      "Epoch 36/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1938 - acc: 0.9693 - val_loss: 1.6730 - val_acc: 0.6089\n",
      "Epoch 37/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1819 - acc: 0.9710 - val_loss: 1.7029 - val_acc: 0.6056\n",
      "Epoch 38/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1736 - acc: 0.9704 - val_loss: 1.7372 - val_acc: 0.6100\n",
      "Epoch 39/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1612 - acc: 0.9734 - val_loss: 1.7616 - val_acc: 0.6046\n",
      "Epoch 40/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1504 - acc: 0.9776 - val_loss: 1.8124 - val_acc: 0.6078\n",
      "Epoch 41/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1418 - acc: 0.9789 - val_loss: 1.8376 - val_acc: 0.6078\n",
      "Epoch 42/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1376 - acc: 0.9777 - val_loss: 1.8649 - val_acc: 0.6078\n",
      "Epoch 43/100\n",
      "130/130 [==============================] - 1s 4ms/step - loss: 0.1284 - acc: 0.9801 - val_loss: 1.8946 - val_acc: 0.6046\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 10, random_state = 82, shuffle = True)\n",
    "\n",
    "result = 0\n",
    "for train_index, valid_index in skf.split(train2,train[\"target\"]): \n",
    "    X_train, X_valid = train2[train_index], train2[valid_index]\n",
    "    y_train, y_valid = train[\"target\"].iloc[train_index], train[\"target\"].iloc[valid_index]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(len(tk.word_index) + 1, 15, input_length = 300))  #\n",
    "    model.add(Dense(128,activation = \"elu\")) # 학습 다양\n",
    "    model.add(Dropout(0.35)) \n",
    "    model.add(Dense(20, activation = \"softmax\"))\n",
    "    model.compile(loss = \"sparse_categorical_crossentropy\", optimizer = \"adam\", metrics = \"acc\")\n",
    "    es = EarlyStopping(patience = 20, restore_best_weights=True)\n",
    "    #rl = ReduceLROnPlateau(patience = 4, verbose = 1, factor = 0.2)\n",
    "    history = model.fit(X_train, y_train, batch_size = 64, validation_data = (X_valid, y_valid), callbacks = [es], epochs = 100)  \n",
    "    result += model.predict(test2) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d712cb37-ad76-490e-a7ee-3b85fa3d9e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9228</th>\n",
       "      <td>9228</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9229</th>\n",
       "      <td>9229</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9230</th>\n",
       "      <td>9230</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9231</th>\n",
       "      <td>9231</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9232</th>\n",
       "      <td>9232</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9233 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  target\n",
       "0        0       3\n",
       "1        1      16\n",
       "2        2      11\n",
       "3        3       8\n",
       "4        4      12\n",
       "...    ...     ...\n",
       "9228  9228      16\n",
       "9229  9229       1\n",
       "9230  9230       4\n",
       "9231  9231      13\n",
       "9232  9232      12\n",
       "\n",
       "[9233 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(\"sample_submission.csv\")\n",
    "sub[\"target\"] = result.argmax(1)\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c52517d2-2546-484e-8713-7c1f83c12504",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub1.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfb586e-0c81-4a95-a8f9-a948befb6e13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
